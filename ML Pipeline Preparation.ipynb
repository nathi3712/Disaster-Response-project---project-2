{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\magagunk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\magagunk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\magagunk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\magagunk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import  f1_score,precision_score,recall_score,accuracy_score,make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import trigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                  0         0         0            0  ...            0   \n",
       "1                  0         0         0            0  ...            0   \n",
       "2                  0         0         0            0  ...            0   \n",
       "3                  0         0         0            0  ...            0   \n",
       "4                  0         0         0            0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "4     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table('MessagesTables',engine)\n",
    "X = df['message']\n",
    "y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    # Tokenize the text - separating the words\n",
    "    words = word_tokenize(text)\n",
    "    #removing stop words such as (is,the, if...)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    # Reduce words to their stems\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    # Reducing words to their root form\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a machine pipeline with RandomForestClassifier as output\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(tokenizer = tokenize, use_idf = True, smooth_idf = True, sublinear_tf = False)),\n",
    "                     ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "                    ])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(tokenizer=<function tokenize at 0x000001A3F33208B0>)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_test = pipeline.predict(X_test)\n",
    "print(y_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Accuracy_F1 (model, X_test, y_test):\n",
    "    '''\n",
    "    Genrating f1 score, precision and recall \n",
    "    Input is model(which will be classification_repor) and X_test & y_test\n",
    "    Output  Prints the Classification report\n",
    "    '''\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i, col in enumerate(y_test):\n",
    "        print(col)\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.41      0.52      1563\n",
      "           1       0.83      0.94      0.88      4944\n",
      "           2       0.42      0.30      0.35        47\n",
      "\n",
      "    accuracy                           0.81      6554\n",
      "   macro avg       0.65      0.55      0.58      6554\n",
      "weighted avg       0.80      0.81      0.79      6554\n",
      "\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5443\n",
      "           1       0.85      0.49      0.62      1111\n",
      "\n",
      "    accuracy                           0.90      6554\n",
      "   macro avg       0.87      0.73      0.78      6554\n",
      "weighted avg       0.89      0.90      0.89      6554\n",
      "\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6521\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      3884\n",
      "           1       0.75      0.70      0.72      2670\n",
      "\n",
      "    accuracy                           0.78      6554\n",
      "   macro avg       0.77      0.77      0.77      6554\n",
      "weighted avg       0.78      0.78      0.78      6554\n",
      "\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      6019\n",
      "           1       0.87      0.09      0.16       535\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.90      0.54      0.56      6554\n",
      "weighted avg       0.92      0.92      0.90      6554\n",
      "\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6210\n",
      "           1       0.90      0.08      0.14       344\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.93      0.54      0.56      6554\n",
      "weighted avg       0.95      0.95      0.93      6554\n",
      "\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6395\n",
      "           1       0.55      0.04      0.07       159\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.76      0.52      0.53      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6438\n",
      "           1       0.25      0.01      0.02       116\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.62      0.50      0.50      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6354\n",
      "           1       0.62      0.07      0.12       200\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.80      0.53      0.55      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6136\n",
      "           1       0.89      0.39      0.54       418\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.92      0.69      0.76      6554\n",
      "weighted avg       0.96      0.96      0.95      6554\n",
      "\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5809\n",
      "           1       0.87      0.62      0.72       745\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.91      0.80      0.84      6554\n",
      "weighted avg       0.94      0.95      0.94      6554\n",
      "\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5973\n",
      "           1       0.82      0.38      0.52       581\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.88      0.69      0.74      6554\n",
      "weighted avg       0.93      0.94      0.93      6554\n",
      "\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6456\n",
      "           1       1.00      0.11      0.20        98\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.99      0.56      0.60      6554\n",
      "weighted avg       0.99      0.99      0.98      6554\n",
      "\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6421\n",
      "           1       0.89      0.06      0.11       133\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.93      0.53      0.55      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6481\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6339\n",
      "           1       0.56      0.02      0.04       215\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.76      0.51      0.51      6554\n",
      "weighted avg       0.95      0.97      0.95      6554\n",
      "\n",
      "death\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6257\n",
      "           1       0.91      0.13      0.23       297\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.93      0.57      0.60      6554\n",
      "weighted avg       0.96      0.96      0.95      6554\n",
      "\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5690\n",
      "           1       0.52      0.03      0.06       864\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.69      0.51      0.50      6554\n",
      "weighted avg       0.82      0.87      0.81      6554\n",
      "\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6143\n",
      "           1       0.50      0.00      0.00       411\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.72      0.50      0.49      6554\n",
      "weighted avg       0.91      0.94      0.91      6554\n",
      "\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6251\n",
      "           1       0.59      0.03      0.06       303\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.77      0.52      0.52      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6231\n",
      "           1       0.76      0.11      0.18       323\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.86      0.55      0.58      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6407\n",
      "           1       1.00      0.03      0.05       147\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.51      0.52      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6511\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6498\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.99      6554\n",
      "\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6530\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6473\n",
      "           1       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6271\n",
      "           1       0.00      0.00      0.00       283\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.92      0.96      0.94      6554\n",
      "\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      4781\n",
      "           1       0.83      0.71      0.77      1773\n",
      "\n",
      "    accuracy                           0.88      6554\n",
      "   macro avg       0.87      0.83      0.84      6554\n",
      "weighted avg       0.88      0.88      0.88      6554\n",
      "\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      6035\n",
      "           1       0.87      0.49      0.63       519\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.92      0.74      0.80      6554\n",
      "weighted avg       0.95      0.95      0.95      6554\n",
      "\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      5949\n",
      "           1       0.76      0.54      0.63       605\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.85      0.76      0.80      6554\n",
      "weighted avg       0.94      0.94      0.94      6554\n",
      "\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6488\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5964\n",
      "           1       0.89      0.79      0.83       590\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.93      0.89      0.91      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6413\n",
      "           1       0.92      0.09      0.16       141\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.95      0.54      0.57      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6219\n",
      "           1       0.69      0.03      0.06       335\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.82      0.52      0.52      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      5282\n",
      "           1       0.77      0.35      0.48      1272\n",
      "\n",
      "    accuracy                           0.85      6554\n",
      "   macro avg       0.82      0.66      0.70      6554\n",
      "weighted avg       0.84      0.85      0.83      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Accuracy_F1(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit to siddhardhan from youtube on this helper code and some research on stackoverflow\n",
    "# Below I am making a function for the f1_score, precision and recall to run through the data of each column\n",
    "\n",
    "def Precision_recall_f1_score(true_value, pred_value):\n",
    "    '''Making a function to put the Classification report in table format.\n",
    "       Input actual values and predicted values\n",
    "       Output is the classification report (shown as weighted, macro and micro)\n",
    "    '''\n",
    "    precision_weighted = precision_score(true_value, pred_value, average = \"weighted\" )\n",
    "    recall_weighted = recall_score(true_value, pred_value, average = \"weighted\")\n",
    "    f1_weighted = f1_score(true_value, pred_value, average = \"weighted\")\n",
    "    precision_macro = precision_score(true_value, pred_value, average = \"macro\" )\n",
    "    recall_macro = recall_score(true_value, pred_value, average = \"macro\")\n",
    "    f1_macro = f1_score(true_value, pred_value, average = \"macro\")\n",
    "    precision_micro = precision_score(true_value, pred_value, average = \"micro\" )\n",
    "    recall_micro = recall_score(true_value, pred_value, average = \"micro\")\n",
    "    f1_micro = f1_score(true_value, pred_value, average = \"micro\")\n",
    "    return {\"Precision_weighted\": precision_weighted, \"Recall_weighted\": recall_weighted,\"F1_Score_weighted\": f1_weighted, \n",
    "            \"Precision_macro\": precision_macro, \"Recall_macro\": recall_macro,\"F1_Score_macro\": f1_macro, \n",
    "            \"Precision_micro\": precision_micro, \"Recall_micro\": recall_micro,\"F1_Score_micro\": f1_micro}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#making a new dataframe to run the f1_score, precision and recall function on each the columns\n",
    "\n",
    "Test_Report = []\n",
    "for m, column in enumerate(y_test.columns):\n",
    "    Report = Precision_recall_f1_score(y_test.loc[:,column],y_predict_test[:,m])\n",
    "    Test_Report.append(Report)\n",
    "Test_Report_df = pd.DataFrame(Test_Report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_weighted</th>\n",
       "      <th>Recall_weighted</th>\n",
       "      <th>F1_Score_weighted</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_Score_macro</th>\n",
       "      <th>Precision_micro</th>\n",
       "      <th>Recall_micro</th>\n",
       "      <th>F1_Score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.797240</td>\n",
       "      <td>0.811108</td>\n",
       "      <td>0.792736</td>\n",
       "      <td>0.651652</td>\n",
       "      <td>0.550830</td>\n",
       "      <td>0.584140</td>\n",
       "      <td>0.811108</td>\n",
       "      <td>0.811108</td>\n",
       "      <td>0.811108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.897925</td>\n",
       "      <td>0.886248</td>\n",
       "      <td>0.874939</td>\n",
       "      <td>0.734022</td>\n",
       "      <td>0.779300</td>\n",
       "      <td>0.897925</td>\n",
       "      <td>0.897925</td>\n",
       "      <td>0.897925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>0.497482</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779050</td>\n",
       "      <td>0.780439</td>\n",
       "      <td>0.779272</td>\n",
       "      <td>0.773748</td>\n",
       "      <td>0.767985</td>\n",
       "      <td>0.770361</td>\n",
       "      <td>0.780439</td>\n",
       "      <td>0.780439</td>\n",
       "      <td>0.780439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.920470</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.895086</td>\n",
       "      <td>0.897647</td>\n",
       "      <td>0.543344</td>\n",
       "      <td>0.560026</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.924474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.948712</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.931281</td>\n",
       "      <td>0.925705</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.559628</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966156</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.965537</td>\n",
       "      <td>0.761035</td>\n",
       "      <td>0.518477</td>\n",
       "      <td>0.529188</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.975893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.973671</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.504077</td>\n",
       "      <td>0.503791</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.970247</td>\n",
       "      <td>0.958405</td>\n",
       "      <td>0.795212</td>\n",
       "      <td>0.531870</td>\n",
       "      <td>0.551258</td>\n",
       "      <td>0.970247</td>\n",
       "      <td>0.970247</td>\n",
       "      <td>0.970247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.955423</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.950325</td>\n",
       "      <td>0.923303</td>\n",
       "      <td>0.694461</td>\n",
       "      <td>0.760978</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.958041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.942692</td>\n",
       "      <td>0.945529</td>\n",
       "      <td>0.941432</td>\n",
       "      <td>0.909280</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.844915</td>\n",
       "      <td>0.945529</td>\n",
       "      <td>0.945529</td>\n",
       "      <td>0.945529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.931898</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.927210</td>\n",
       "      <td>0.881025</td>\n",
       "      <td>0.686948</td>\n",
       "      <td>0.743918</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.937748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.986902</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.981473</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.556122</td>\n",
       "      <td>0.597571</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.979034</td>\n",
       "      <td>0.980775</td>\n",
       "      <td>0.972473</td>\n",
       "      <td>0.934895</td>\n",
       "      <td>0.529997</td>\n",
       "      <td>0.551479</td>\n",
       "      <td>0.980775</td>\n",
       "      <td>0.980775</td>\n",
       "      <td>0.980775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.983324</td>\n",
       "      <td>0.494431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.988862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.954387</td>\n",
       "      <td>0.967348</td>\n",
       "      <td>0.952595</td>\n",
       "      <td>0.761735</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.514017</td>\n",
       "      <td>0.967348</td>\n",
       "      <td>0.967348</td>\n",
       "      <td>0.967348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.957955</td>\n",
       "      <td>0.960024</td>\n",
       "      <td>0.945490</td>\n",
       "      <td>0.933676</td>\n",
       "      <td>0.565337</td>\n",
       "      <td>0.604446</td>\n",
       "      <td>0.960024</td>\n",
       "      <td>0.960024</td>\n",
       "      <td>0.960024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.824867</td>\n",
       "      <td>0.868477</td>\n",
       "      <td>0.814822</td>\n",
       "      <td>0.694952</td>\n",
       "      <td>0.513919</td>\n",
       "      <td>0.495144</td>\n",
       "      <td>0.868477</td>\n",
       "      <td>0.868477</td>\n",
       "      <td>0.868477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.907249</td>\n",
       "      <td>0.718712</td>\n",
       "      <td>0.501135</td>\n",
       "      <td>0.486234</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.937290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.938214</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.934283</td>\n",
       "      <td>0.771707</td>\n",
       "      <td>0.515942</td>\n",
       "      <td>0.519520</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.954226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.945741</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.937436</td>\n",
       "      <td>0.855578</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.580617</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.954226</td>\n",
       "      <td>0.954226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.978658</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.967970</td>\n",
       "      <td>0.989084</td>\n",
       "      <td>0.513605</td>\n",
       "      <td>0.520972</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.978181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.990169</td>\n",
       "      <td>0.496720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498354</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.982983</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.987125</td>\n",
       "      <td>0.495727</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.975435</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.493821</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496891</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.987641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>0.478410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.956820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.880222</td>\n",
       "      <td>0.882820</td>\n",
       "      <td>0.879627</td>\n",
       "      <td>0.865646</td>\n",
       "      <td>0.827775</td>\n",
       "      <td>0.843791</td>\n",
       "      <td>0.882820</td>\n",
       "      <td>0.882820</td>\n",
       "      <td>0.882820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.950970</td>\n",
       "      <td>0.953921</td>\n",
       "      <td>0.947863</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.741636</td>\n",
       "      <td>0.801302</td>\n",
       "      <td>0.953921</td>\n",
       "      <td>0.953921</td>\n",
       "      <td>0.953921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.935764</td>\n",
       "      <td>0.941105</td>\n",
       "      <td>0.936522</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>0.758944</td>\n",
       "      <td>0.797361</td>\n",
       "      <td>0.941105</td>\n",
       "      <td>0.941105</td>\n",
       "      <td>0.941105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.979960</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.494964</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497431</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.971926</td>\n",
       "      <td>0.971171</td>\n",
       "      <td>0.933337</td>\n",
       "      <td>0.889121</td>\n",
       "      <td>0.909744</td>\n",
       "      <td>0.971926</td>\n",
       "      <td>0.971926</td>\n",
       "      <td>0.971926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.979048</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.972020</td>\n",
       "      <td>0.951678</td>\n",
       "      <td>0.542475</td>\n",
       "      <td>0.572904</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.937004</td>\n",
       "      <td>0.949802</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.516016</td>\n",
       "      <td>0.518444</td>\n",
       "      <td>0.949802</td>\n",
       "      <td>0.949802</td>\n",
       "      <td>0.949802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.844392</td>\n",
       "      <td>0.853982</td>\n",
       "      <td>0.831239</td>\n",
       "      <td>0.816565</td>\n",
       "      <td>0.663511</td>\n",
       "      <td>0.699256</td>\n",
       "      <td>0.853982</td>\n",
       "      <td>0.853982</td>\n",
       "      <td>0.853982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision_weighted  Recall_weighted  F1_Score_weighted  Precision_macro  \\\n",
       "0             0.797240         0.811108           0.792736         0.651652   \n",
       "1             0.893805         0.897925           0.886248         0.874939   \n",
       "2             0.989955         0.994965           0.992454         0.497482   \n",
       "3             0.779050         0.780439           0.779272         0.773748   \n",
       "4             0.920470         0.924474           0.895086         0.897647   \n",
       "5             0.948712         0.951175           0.931281         0.925705   \n",
       "6             0.966156         0.975893           0.965537         0.761035   \n",
       "7             0.969479         0.981996           0.973671         0.616221   \n",
       "8             0.960625         0.970247           0.958405         0.795212   \n",
       "9             1.000000         1.000000           1.000000         1.000000   \n",
       "10            0.955423         0.958041           0.950325         0.923303   \n",
       "11            0.942692         0.945529           0.941432         0.909280   \n",
       "12            0.931898         0.937748           0.927210         0.881025   \n",
       "13            0.986902         0.986726           0.981473         0.993352   \n",
       "14            0.979034         0.980775           0.972473         0.934895   \n",
       "15            0.977848         0.988862           0.983324         0.494431   \n",
       "16            0.954387         0.967348           0.952595         0.761735   \n",
       "17            0.957955         0.960024           0.945490         0.933676   \n",
       "18            0.824867         0.868477           0.814822         0.694952   \n",
       "19            0.909993         0.937290           0.907249         0.718712   \n",
       "20            0.938214         0.954226           0.934283         0.771707   \n",
       "21            0.945741         0.954226           0.937436         0.855578   \n",
       "22            0.978658         0.978181           0.967970         0.989084   \n",
       "23            0.986921         0.993439           0.990169         0.496720   \n",
       "24            0.982983         0.991303           0.987125         0.495727   \n",
       "25            0.992690         0.996338           0.994511         0.498169   \n",
       "26            0.975435         0.987641           0.981500         0.493821   \n",
       "27            0.915505         0.956820           0.935707         0.478410   \n",
       "28            0.880222         0.882820           0.879627         0.865646   \n",
       "29            0.950970         0.953921           0.947863         0.915270   \n",
       "30            0.935764         0.941105           0.936522         0.854684   \n",
       "31            0.979960         0.989777           0.984844         0.494964   \n",
       "32            0.971000         0.971926           0.971171         0.933337   \n",
       "33            0.979048         0.980165           0.972020         0.951678   \n",
       "34            0.937004         0.949802           0.927618         0.818972   \n",
       "35            0.844392         0.853982           0.831239         0.816565   \n",
       "\n",
       "    Recall_macro  F1_Score_macro  Precision_micro  Recall_micro  \\\n",
       "0       0.550830        0.584140         0.811108      0.811108   \n",
       "1       0.734022        0.779300         0.897925      0.897925   \n",
       "2       0.500000        0.498738         0.994965      0.994965   \n",
       "3       0.767985        0.770361         0.780439      0.780439   \n",
       "4       0.543344        0.560026         0.924474      0.924474   \n",
       "5       0.539003        0.559628         0.951175      0.951175   \n",
       "6       0.518477        0.529188         0.975893      0.975893   \n",
       "7       0.504077        0.503791         0.981996      0.981996   \n",
       "8       0.531870        0.551258         0.970247      0.970247   \n",
       "9       1.000000        1.000000         1.000000      1.000000   \n",
       "10      0.694461        0.760978         0.958041      0.958041   \n",
       "11      0.801942        0.844915         0.945529      0.945529   \n",
       "12      0.686948        0.743918         0.937748      0.937748   \n",
       "13      0.556122        0.597571         0.986726      0.986726   \n",
       "14      0.529997        0.551479         0.980775      0.980775   \n",
       "15      0.500000        0.497200         0.988862      0.988862   \n",
       "16      0.511312        0.514017         0.967348      0.967348   \n",
       "17      0.565337        0.604446         0.960024      0.960024   \n",
       "18      0.513919        0.495144         0.868477      0.868477   \n",
       "19      0.501135        0.486234         0.937290      0.937290   \n",
       "20      0.515942        0.519520         0.954226      0.954226   \n",
       "21      0.551749        0.580617         0.954226      0.954226   \n",
       "22      0.513605        0.520972         0.978181      0.978181   \n",
       "23      0.500000        0.498354         0.993439      0.993439   \n",
       "24      0.499923        0.497816         0.991303      0.991303   \n",
       "25      0.500000        0.499083         0.996338      0.996338   \n",
       "26      0.500000        0.496891         0.987641      0.987641   \n",
       "27      0.500000        0.488967         0.956820      0.956820   \n",
       "28      0.827775        0.843791         0.882820      0.882820   \n",
       "29      0.741636        0.801302         0.953921      0.953921   \n",
       "30      0.758944        0.797361         0.941105      0.941105   \n",
       "31      0.499923        0.497431         0.989777      0.989777   \n",
       "32      0.889121        0.909744         0.971926      0.971926   \n",
       "33      0.542475        0.572904         0.980165      0.980165   \n",
       "34      0.516016        0.518444         0.949802      0.949802   \n",
       "35      0.663511        0.699256         0.853982      0.853982   \n",
       "\n",
       "    F1_Score_micro  \n",
       "0         0.811108  \n",
       "1         0.897925  \n",
       "2         0.994965  \n",
       "3         0.780439  \n",
       "4         0.924474  \n",
       "5         0.951175  \n",
       "6         0.975893  \n",
       "7         0.981996  \n",
       "8         0.970247  \n",
       "9         1.000000  \n",
       "10        0.958041  \n",
       "11        0.945529  \n",
       "12        0.937748  \n",
       "13        0.986726  \n",
       "14        0.980775  \n",
       "15        0.988862  \n",
       "16        0.967348  \n",
       "17        0.960024  \n",
       "18        0.868477  \n",
       "19        0.937290  \n",
       "20        0.954226  \n",
       "21        0.954226  \n",
       "22        0.978181  \n",
       "23        0.993439  \n",
       "24        0.991303  \n",
       "25        0.996338  \n",
       "26        0.987641  \n",
       "27        0.956820  \n",
       "28        0.882820  \n",
       "29        0.953921  \n",
       "30        0.941105  \n",
       "31        0.989777  \n",
       "32        0.971926  \n",
       "33        0.980165  \n",
       "34        0.949802  \n",
       "35        0.853982  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Report_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision_weighted    0.940028\n",
       "Recall_weighted       0.948742\n",
       "F1_Score_weighted     0.936964\n",
       "Precision_macro       0.771370\n",
       "Recall_macro          0.599206\n",
       "F1_Score_macro        0.615966\n",
       "Precision_micro       0.948742\n",
       "Recall_micro          0.948742\n",
       "F1_Score_micro        0.948742\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Report_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding GridSearchCV and tuning parameters\n",
    "parameters = {'vect__max_df': (0.5, 1.0),\n",
    "              'clf__estimator__n_estimators': [5, 10, 20],\n",
    "              'clf__estimator__min_samples_split': [2]}\n",
    "\n",
    "CV = GridSearchCV(pipeline, param_grid = parameters, cv = 3, refit = True, return_train_score = True,verbose=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 3,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('vect',\n",
       "   TfidfVectorizer(tokenizer=<function tokenize at 0x000001A3F33208B0>)),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__vect': TfidfVectorizer(tokenizer=<function tokenize at 0x000001A3F33208B0>),\n",
       " 'estimator__clf': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'estimator__vect__analyzer': 'word',\n",
       " 'estimator__vect__binary': False,\n",
       " 'estimator__vect__decode_error': 'strict',\n",
       " 'estimator__vect__dtype': numpy.float64,\n",
       " 'estimator__vect__encoding': 'utf-8',\n",
       " 'estimator__vect__input': 'content',\n",
       " 'estimator__vect__lowercase': True,\n",
       " 'estimator__vect__max_df': 1.0,\n",
       " 'estimator__vect__max_features': None,\n",
       " 'estimator__vect__min_df': 1,\n",
       " 'estimator__vect__ngram_range': (1, 1),\n",
       " 'estimator__vect__norm': 'l2',\n",
       " 'estimator__vect__preprocessor': None,\n",
       " 'estimator__vect__smooth_idf': True,\n",
       " 'estimator__vect__stop_words': None,\n",
       " 'estimator__vect__strip_accents': None,\n",
       " 'estimator__vect__sublinear_tf': False,\n",
       " 'estimator__vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'estimator__vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'estimator__vect__use_idf': True,\n",
       " 'estimator__vect__vocabulary': None,\n",
       " 'estimator__clf__estimator__bootstrap': True,\n",
       " 'estimator__clf__estimator__ccp_alpha': 0.0,\n",
       " 'estimator__clf__estimator__class_weight': None,\n",
       " 'estimator__clf__estimator__criterion': 'gini',\n",
       " 'estimator__clf__estimator__max_depth': None,\n",
       " 'estimator__clf__estimator__max_features': 'sqrt',\n",
       " 'estimator__clf__estimator__max_leaf_nodes': None,\n",
       " 'estimator__clf__estimator__max_samples': None,\n",
       " 'estimator__clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__clf__estimator__min_samples_leaf': 1,\n",
       " 'estimator__clf__estimator__min_samples_split': 2,\n",
       " 'estimator__clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__clf__estimator__n_estimators': 100,\n",
       " 'estimator__clf__estimator__n_jobs': None,\n",
       " 'estimator__clf__estimator__oob_score': False,\n",
       " 'estimator__clf__estimator__random_state': None,\n",
       " 'estimator__clf__estimator__verbose': 0,\n",
       " 'estimator__clf__estimator__warm_start': False,\n",
       " 'estimator__clf__estimator': RandomForestClassifier(),\n",
       " 'estimator__clf__n_jobs': None,\n",
       " 'estimator': Pipeline(steps=[('vect',\n",
       "                  TfidfVectorizer(tokenizer=<function tokenize at 0x000001A3F33208B0>)),\n",
       "                 ('clf',\n",
       "                  MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'vect__max_df': (0.5, 1.0),\n",
       "  'clf__estimator__n_estimators': [5, 10, 20],\n",
       "  'clf__estimator__min_samples_split': [2]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': None,\n",
       " 'verbose': 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=(train=0.759, test=0.191) total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=(train=0.754, test=0.201) total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=(train=0.764, test=0.204) total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=1.0;, score=(train=0.755, test=0.198) total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=1.0;, score=(train=0.755, test=0.199) total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=1.0;, score=(train=0.758, test=0.200) total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=(train=0.820, test=0.233) total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=(train=0.817, test=0.245) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=(train=0.811, test=0.243) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=1.0;, score=(train=0.816, test=0.237) total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=1.0;, score=(train=0.815, test=0.238) total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=1.0;, score=(train=0.814, test=0.234) total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=0.5;, score=(train=0.913, test=0.247) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=0.5;, score=(train=0.913, test=0.255) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=0.5;, score=(train=0.917, test=0.253) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=1.0;, score=(train=0.910, test=0.242) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=1.0;, score=(train=0.914, test=0.256) total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=20, vect__max_df=1.0;, score=(train=0.914, test=0.245) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [5, 10, 20],\n",
       "                         &#x27;vect__max_df&#x27;: (0.5, 1.0)},\n",
       "             return_train_score=True, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [5, 10, 20],\n",
       "                         &#x27;vect__max_df&#x27;: (0.5, 1.0)},\n",
       "             return_train_score=True, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000001A3F33208B0&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(tokenizer=<function tokenize at 0x000001A3F33208B0>)),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={'clf__estimator__min_samples_split': [2],\n",
       "                         'clf__estimator__n_estimators': [5, 10, 20],\n",
       "                         'vect__max_df': (0.5, 1.0)},\n",
       "             return_train_score=True, verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict against the refined model with GriSearchCV and RandomForestClassifier\n",
    "version2_model = CV.best_estimator_\n",
    "y_predict_test2 = version2_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_weighted</th>\n",
       "      <th>Recall_weighted</th>\n",
       "      <th>F1_Score_weighted</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_Score_macro</th>\n",
       "      <th>Precision_micro</th>\n",
       "      <th>Recall_micro</th>\n",
       "      <th>F1_Score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787594</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.787596</td>\n",
       "      <td>0.618326</td>\n",
       "      <td>0.557647</td>\n",
       "      <td>0.578661</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.802716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884794</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.876803</td>\n",
       "      <td>0.860491</td>\n",
       "      <td>0.715193</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.890449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>0.497482</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762519</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.761614</td>\n",
       "      <td>0.758869</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.764419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907716</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.896781</td>\n",
       "      <td>0.812541</td>\n",
       "      <td>0.552129</td>\n",
       "      <td>0.573755</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.923406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.929992</td>\n",
       "      <td>0.875475</td>\n",
       "      <td>0.534401</td>\n",
       "      <td>0.551371</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.950259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.964830</td>\n",
       "      <td>0.710381</td>\n",
       "      <td>0.512188</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.975587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.973671</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.504077</td>\n",
       "      <td>0.503791</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.959363</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.754628</td>\n",
       "      <td>0.553505</td>\n",
       "      <td>0.583631</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.969942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.949841</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.943629</td>\n",
       "      <td>0.908335</td>\n",
       "      <td>0.660887</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.953616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939323</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.938146</td>\n",
       "      <td>0.901598</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.835857</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.942630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.922475</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.916315</td>\n",
       "      <td>0.860312</td>\n",
       "      <td>0.646584</td>\n",
       "      <td>0.699212</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.930729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.856759</td>\n",
       "      <td>0.540584</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.985810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.976643</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.971064</td>\n",
       "      <td>0.890151</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>0.523974</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.989284</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.984069</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>0.513699</td>\n",
       "      <td>0.523943</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.989167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.951870</td>\n",
       "      <td>0.698095</td>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.505132</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.967043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.951952</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.946412</td>\n",
       "      <td>0.857721</td>\n",
       "      <td>0.576242</td>\n",
       "      <td>0.618060</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.959414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.827367</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>0.703684</td>\n",
       "      <td>0.515076</td>\n",
       "      <td>0.497328</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.868782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.878495</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.906798</td>\n",
       "      <td>0.468636</td>\n",
       "      <td>0.499837</td>\n",
       "      <td>0.483734</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.936985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.938904</td>\n",
       "      <td>0.816509</td>\n",
       "      <td>0.540294</td>\n",
       "      <td>0.562173</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.951059</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.906535</td>\n",
       "      <td>0.555246</td>\n",
       "      <td>0.587134</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.955294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.974169</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>0.889082</td>\n",
       "      <td>0.513527</td>\n",
       "      <td>0.520759</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.978029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.990169</td>\n",
       "      <td>0.496720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498354</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.982983</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.987125</td>\n",
       "      <td>0.495727</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.975433</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>0.493820</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.496852</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.987489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915480</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.935402</td>\n",
       "      <td>0.478397</td>\n",
       "      <td>0.499681</td>\n",
       "      <td>0.488807</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.956210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.866419</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.851742</td>\n",
       "      <td>0.805119</td>\n",
       "      <td>0.823838</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.869698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.947779</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.944080</td>\n",
       "      <td>0.909706</td>\n",
       "      <td>0.724295</td>\n",
       "      <td>0.784989</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.934898</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.935793</td>\n",
       "      <td>0.850811</td>\n",
       "      <td>0.757781</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.940342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.979960</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.494964</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497431</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.962109</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.961884</td>\n",
       "      <td>0.924922</td>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.963839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.976092</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.969607</td>\n",
       "      <td>0.906282</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.979097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.927426</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.928554</td>\n",
       "      <td>0.718467</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.532757</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.948734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.835816</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.801222</td>\n",
       "      <td>0.651463</td>\n",
       "      <td>0.684578</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.848032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision_weighted  Recall_weighted  F1_Score_weighted  Precision_macro  \\\n",
       "0             0.787594         0.802716           0.787596         0.618326   \n",
       "1             0.884794         0.890449           0.876803         0.860491   \n",
       "2             0.989955         0.994965           0.992454         0.497482   \n",
       "3             0.762519         0.764419           0.761614         0.758869   \n",
       "4             0.907716         0.923406           0.896781         0.812541   \n",
       "5             0.943027         0.950259           0.929992         0.875475   \n",
       "6             0.963415         0.975587           0.964830         0.710381   \n",
       "7             0.969479         0.981996           0.973671         0.616221   \n",
       "8             0.959363         0.969942           0.960212         0.754628   \n",
       "9             1.000000         1.000000           1.000000         1.000000   \n",
       "10            0.949841         0.953616           0.943629         0.908335   \n",
       "11            0.939323         0.942630           0.938146         0.901598   \n",
       "12            0.922475         0.930729           0.916315         0.860312   \n",
       "13            0.982373         0.985810           0.980195         0.856759   \n",
       "14            0.976643         0.980165           0.971064         0.890151   \n",
       "15            0.989284         0.989167           0.984069         0.994582   \n",
       "16            0.949936         0.967043           0.951870         0.698095   \n",
       "17            0.951952         0.959414           0.946412         0.857721   \n",
       "18            0.827367         0.868782           0.815510         0.703684   \n",
       "19            0.878495         0.936985           0.906798         0.468636   \n",
       "20            0.944321         0.955752           0.938904         0.816509   \n",
       "21            0.951059         0.955294           0.938579         0.906535   \n",
       "22            0.974169         0.978029           0.967886         0.889082   \n",
       "23            0.986921         0.993439           0.990169         0.496720   \n",
       "24            0.982983         0.991303           0.987125         0.495727   \n",
       "25            0.992690         0.996338           0.994511         0.498169   \n",
       "26            0.975433         0.987489           0.981424         0.493820   \n",
       "27            0.915480         0.956210           0.935402         0.478397   \n",
       "28            0.866419         0.869698           0.865090         0.851742   \n",
       "29            0.947779         0.951175           0.944080         0.909706   \n",
       "30            0.934898         0.940342           0.935793         0.850811   \n",
       "31            0.979960         0.989777           0.984844         0.494964   \n",
       "32            0.962109         0.963839           0.961884         0.924922   \n",
       "33            0.976092         0.979097           0.969607         0.906282   \n",
       "34            0.927426         0.948734           0.928554         0.718467   \n",
       "35            0.835816         0.848032           0.823503         0.801222   \n",
       "\n",
       "    Recall_macro  F1_Score_macro  Precision_micro  Recall_micro  \\\n",
       "0       0.557647        0.578661         0.802716      0.802716   \n",
       "1       0.715193        0.759517         0.890449      0.890449   \n",
       "2       0.500000        0.498738         0.994965      0.994965   \n",
       "3       0.746800        0.750840         0.764419      0.764419   \n",
       "4       0.552129        0.573755         0.923406      0.923406   \n",
       "5       0.534401        0.551371         0.950259      0.950259   \n",
       "6       0.512188        0.517627         0.975587      0.975587   \n",
       "7       0.504077        0.503791         0.981996      0.981996   \n",
       "8       0.553505        0.583631         0.969942      0.969942   \n",
       "9       1.000000        1.000000         1.000000      1.000000   \n",
       "10      0.660887        0.723982         0.953616      0.953616   \n",
       "11      0.792701        0.835857         0.942630      0.942630   \n",
       "12      0.646584        0.699212         0.930729      0.930729   \n",
       "13      0.540584        0.569817         0.985810      0.985810   \n",
       "14      0.514960        0.523974         0.980165      0.980165   \n",
       "15      0.513699        0.523943         0.989167      0.989167   \n",
       "16      0.506661        0.505132         0.967043      0.967043   \n",
       "17      0.576242        0.618060         0.959414      0.959414   \n",
       "18      0.515076        0.497328         0.868782      0.868782   \n",
       "19      0.499837        0.483734         0.936985      0.936985   \n",
       "20      0.540294        0.562173         0.955752      0.955752   \n",
       "21      0.555246        0.587134         0.955294      0.955294   \n",
       "22      0.513527        0.520759         0.978029      0.978029   \n",
       "23      0.500000        0.498354         0.993439      0.993439   \n",
       "24      0.499923        0.497816         0.991303      0.991303   \n",
       "25      0.500000        0.499083         0.996338      0.996338   \n",
       "26      0.499923        0.496852         0.987489      0.987489   \n",
       "27      0.499681        0.488807         0.956210      0.956210   \n",
       "28      0.805119        0.823838         0.869698      0.869698   \n",
       "29      0.724295        0.784989         0.951175      0.951175   \n",
       "30      0.757781        0.795280         0.940342      0.940342   \n",
       "31      0.499923        0.497431         0.989777      0.989777   \n",
       "32      0.841915        0.877846         0.963839      0.963839   \n",
       "33      0.517653        0.528729         0.979097      0.979097   \n",
       "34      0.523926        0.532757         0.948734      0.948734   \n",
       "35      0.651463        0.684578         0.848032      0.848032   \n",
       "\n",
       "    F1_Score_micro  \n",
       "0         0.802716  \n",
       "1         0.890449  \n",
       "2         0.994965  \n",
       "3         0.764419  \n",
       "4         0.923406  \n",
       "5         0.950259  \n",
       "6         0.975587  \n",
       "7         0.981996  \n",
       "8         0.969942  \n",
       "9         1.000000  \n",
       "10        0.953616  \n",
       "11        0.942630  \n",
       "12        0.930729  \n",
       "13        0.985810  \n",
       "14        0.980165  \n",
       "15        0.989167  \n",
       "16        0.967043  \n",
       "17        0.959414  \n",
       "18        0.868782  \n",
       "19        0.936985  \n",
       "20        0.955752  \n",
       "21        0.955294  \n",
       "22        0.978029  \n",
       "23        0.993439  \n",
       "24        0.991303  \n",
       "25        0.996338  \n",
       "26        0.987489  \n",
       "27        0.956210  \n",
       "28        0.869698  \n",
       "29        0.951175  \n",
       "30        0.940342  \n",
       "31        0.989777  \n",
       "32        0.963839  \n",
       "33        0.979097  \n",
       "34        0.948734  \n",
       "35        0.848032  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the outcome of the tuning in a dataframe format\n",
    "Test_Report2 = []\n",
    "for m, column in enumerate(y_test.columns):\n",
    "    Report = Precision_recall_f1_score(y_test.loc[:,column], y_predict_test2[:, m])\n",
    "    Test_Report2.append(Report)\n",
    "Test_Report2_df = pd.DataFrame(Test_Report2)\n",
    "Test_Report2_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_weighted</th>\n",
       "      <th>Recall_weighted</th>\n",
       "      <th>F1_Score_weighted</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_Score_macro</th>\n",
       "      <th>Precision_micro</th>\n",
       "      <th>Recall_micro</th>\n",
       "      <th>F1_Score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787594</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.787596</td>\n",
       "      <td>0.618326</td>\n",
       "      <td>0.557647</td>\n",
       "      <td>0.578661</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.802716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884794</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.876803</td>\n",
       "      <td>0.860491</td>\n",
       "      <td>0.715193</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.890449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>0.497482</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762519</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.761614</td>\n",
       "      <td>0.758869</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.764419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907716</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.896781</td>\n",
       "      <td>0.812541</td>\n",
       "      <td>0.552129</td>\n",
       "      <td>0.573755</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.923406</td>\n",
       "      <td>0.923406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.929992</td>\n",
       "      <td>0.875475</td>\n",
       "      <td>0.534401</td>\n",
       "      <td>0.551371</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.950259</td>\n",
       "      <td>0.950259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.964830</td>\n",
       "      <td>0.710381</td>\n",
       "      <td>0.512188</td>\n",
       "      <td>0.517627</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>0.975587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.973671</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.504077</td>\n",
       "      <td>0.503791</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.981996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.959363</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.754628</td>\n",
       "      <td>0.553505</td>\n",
       "      <td>0.583631</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.969942</td>\n",
       "      <td>0.969942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.949841</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.943629</td>\n",
       "      <td>0.908335</td>\n",
       "      <td>0.660887</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.953616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939323</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.938146</td>\n",
       "      <td>0.901598</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.835857</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.942630</td>\n",
       "      <td>0.942630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.922475</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.916315</td>\n",
       "      <td>0.860312</td>\n",
       "      <td>0.646584</td>\n",
       "      <td>0.699212</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.930729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.856759</td>\n",
       "      <td>0.540584</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.985810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.976643</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.971064</td>\n",
       "      <td>0.890151</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>0.523974</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.980165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.989284</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.984069</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>0.513699</td>\n",
       "      <td>0.523943</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.989167</td>\n",
       "      <td>0.989167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.951870</td>\n",
       "      <td>0.698095</td>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.505132</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.967043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.951952</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.946412</td>\n",
       "      <td>0.857721</td>\n",
       "      <td>0.576242</td>\n",
       "      <td>0.618060</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.959414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.827367</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>0.703684</td>\n",
       "      <td>0.515076</td>\n",
       "      <td>0.497328</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.868782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.878495</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.906798</td>\n",
       "      <td>0.468636</td>\n",
       "      <td>0.499837</td>\n",
       "      <td>0.483734</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.936985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.938904</td>\n",
       "      <td>0.816509</td>\n",
       "      <td>0.540294</td>\n",
       "      <td>0.562173</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.951059</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.906535</td>\n",
       "      <td>0.555246</td>\n",
       "      <td>0.587134</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.955294</td>\n",
       "      <td>0.955294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.974169</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>0.889082</td>\n",
       "      <td>0.513527</td>\n",
       "      <td>0.520759</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.978029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.990169</td>\n",
       "      <td>0.496720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498354</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.982983</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.987125</td>\n",
       "      <td>0.495727</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>0.991303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.975433</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>0.493820</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.496852</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.987489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915480</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.935402</td>\n",
       "      <td>0.478397</td>\n",
       "      <td>0.499681</td>\n",
       "      <td>0.488807</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>0.956210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.866419</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.851742</td>\n",
       "      <td>0.805119</td>\n",
       "      <td>0.823838</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.869698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.947779</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.944080</td>\n",
       "      <td>0.909706</td>\n",
       "      <td>0.724295</td>\n",
       "      <td>0.784989</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.951175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.934898</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.935793</td>\n",
       "      <td>0.850811</td>\n",
       "      <td>0.757781</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.940342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.979960</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.494964</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.497431</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.962109</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.961884</td>\n",
       "      <td>0.924922</td>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.963839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.976092</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.969607</td>\n",
       "      <td>0.906282</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.979097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.927426</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.928554</td>\n",
       "      <td>0.718467</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.532757</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.948734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.835816</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.801222</td>\n",
       "      <td>0.651463</td>\n",
       "      <td>0.684578</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.848032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision_weighted  Recall_weighted  F1_Score_weighted  Precision_macro  \\\n",
       "0             0.787594         0.802716           0.787596         0.618326   \n",
       "1             0.884794         0.890449           0.876803         0.860491   \n",
       "2             0.989955         0.994965           0.992454         0.497482   \n",
       "3             0.762519         0.764419           0.761614         0.758869   \n",
       "4             0.907716         0.923406           0.896781         0.812541   \n",
       "5             0.943027         0.950259           0.929992         0.875475   \n",
       "6             0.963415         0.975587           0.964830         0.710381   \n",
       "7             0.969479         0.981996           0.973671         0.616221   \n",
       "8             0.959363         0.969942           0.960212         0.754628   \n",
       "9             1.000000         1.000000           1.000000         1.000000   \n",
       "10            0.949841         0.953616           0.943629         0.908335   \n",
       "11            0.939323         0.942630           0.938146         0.901598   \n",
       "12            0.922475         0.930729           0.916315         0.860312   \n",
       "13            0.982373         0.985810           0.980195         0.856759   \n",
       "14            0.976643         0.980165           0.971064         0.890151   \n",
       "15            0.989284         0.989167           0.984069         0.994582   \n",
       "16            0.949936         0.967043           0.951870         0.698095   \n",
       "17            0.951952         0.959414           0.946412         0.857721   \n",
       "18            0.827367         0.868782           0.815510         0.703684   \n",
       "19            0.878495         0.936985           0.906798         0.468636   \n",
       "20            0.944321         0.955752           0.938904         0.816509   \n",
       "21            0.951059         0.955294           0.938579         0.906535   \n",
       "22            0.974169         0.978029           0.967886         0.889082   \n",
       "23            0.986921         0.993439           0.990169         0.496720   \n",
       "24            0.982983         0.991303           0.987125         0.495727   \n",
       "25            0.992690         0.996338           0.994511         0.498169   \n",
       "26            0.975433         0.987489           0.981424         0.493820   \n",
       "27            0.915480         0.956210           0.935402         0.478397   \n",
       "28            0.866419         0.869698           0.865090         0.851742   \n",
       "29            0.947779         0.951175           0.944080         0.909706   \n",
       "30            0.934898         0.940342           0.935793         0.850811   \n",
       "31            0.979960         0.989777           0.984844         0.494964   \n",
       "32            0.962109         0.963839           0.961884         0.924922   \n",
       "33            0.976092         0.979097           0.969607         0.906282   \n",
       "34            0.927426         0.948734           0.928554         0.718467   \n",
       "35            0.835816         0.848032           0.823503         0.801222   \n",
       "\n",
       "    Recall_macro  F1_Score_macro  Precision_micro  Recall_micro  \\\n",
       "0       0.557647        0.578661         0.802716      0.802716   \n",
       "1       0.715193        0.759517         0.890449      0.890449   \n",
       "2       0.500000        0.498738         0.994965      0.994965   \n",
       "3       0.746800        0.750840         0.764419      0.764419   \n",
       "4       0.552129        0.573755         0.923406      0.923406   \n",
       "5       0.534401        0.551371         0.950259      0.950259   \n",
       "6       0.512188        0.517627         0.975587      0.975587   \n",
       "7       0.504077        0.503791         0.981996      0.981996   \n",
       "8       0.553505        0.583631         0.969942      0.969942   \n",
       "9       1.000000        1.000000         1.000000      1.000000   \n",
       "10      0.660887        0.723982         0.953616      0.953616   \n",
       "11      0.792701        0.835857         0.942630      0.942630   \n",
       "12      0.646584        0.699212         0.930729      0.930729   \n",
       "13      0.540584        0.569817         0.985810      0.985810   \n",
       "14      0.514960        0.523974         0.980165      0.980165   \n",
       "15      0.513699        0.523943         0.989167      0.989167   \n",
       "16      0.506661        0.505132         0.967043      0.967043   \n",
       "17      0.576242        0.618060         0.959414      0.959414   \n",
       "18      0.515076        0.497328         0.868782      0.868782   \n",
       "19      0.499837        0.483734         0.936985      0.936985   \n",
       "20      0.540294        0.562173         0.955752      0.955752   \n",
       "21      0.555246        0.587134         0.955294      0.955294   \n",
       "22      0.513527        0.520759         0.978029      0.978029   \n",
       "23      0.500000        0.498354         0.993439      0.993439   \n",
       "24      0.499923        0.497816         0.991303      0.991303   \n",
       "25      0.500000        0.499083         0.996338      0.996338   \n",
       "26      0.499923        0.496852         0.987489      0.987489   \n",
       "27      0.499681        0.488807         0.956210      0.956210   \n",
       "28      0.805119        0.823838         0.869698      0.869698   \n",
       "29      0.724295        0.784989         0.951175      0.951175   \n",
       "30      0.757781        0.795280         0.940342      0.940342   \n",
       "31      0.499923        0.497431         0.989777      0.989777   \n",
       "32      0.841915        0.877846         0.963839      0.963839   \n",
       "33      0.517653        0.528729         0.979097      0.979097   \n",
       "34      0.523926        0.532757         0.948734      0.948734   \n",
       "35      0.651463        0.684578         0.848032      0.848032   \n",
       "\n",
       "    F1_Score_micro  \n",
       "0         0.802716  \n",
       "1         0.890449  \n",
       "2         0.994965  \n",
       "3         0.764419  \n",
       "4         0.923406  \n",
       "5         0.950259  \n",
       "6         0.975587  \n",
       "7         0.981996  \n",
       "8         0.969942  \n",
       "9         1.000000  \n",
       "10        0.953616  \n",
       "11        0.942630  \n",
       "12        0.930729  \n",
       "13        0.985810  \n",
       "14        0.980165  \n",
       "15        0.989167  \n",
       "16        0.967043  \n",
       "17        0.959414  \n",
       "18        0.868782  \n",
       "19        0.936985  \n",
       "20        0.955752  \n",
       "21        0.955294  \n",
       "22        0.978029  \n",
       "23        0.993439  \n",
       "24        0.991303  \n",
       "25        0.996338  \n",
       "26        0.987489  \n",
       "27        0.956210  \n",
       "28        0.869698  \n",
       "29        0.951175  \n",
       "30        0.940342  \n",
       "31        0.989777  \n",
       "32        0.963839  \n",
       "33        0.979097  \n",
       "34        0.948734  \n",
       "35        0.848032  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scores for each column\n",
    "Test_Report2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision_weighted    0.935808\n",
       "Recall_weighted       0.946462\n",
       "F1_Score_weighted     0.934592\n",
       "Precision_macro       0.754927\n",
       "Recall_macro          0.593718\n",
       "F1_Score_macro        0.610428\n",
       "Precision_micro       0.946462\n",
       "Recall_micro          0.946462\n",
       "F1_Score_micro        0.946462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of scores\n",
    "Test_Report2_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a machine pipeline with AdaBoostClassifier and adding new features as output\n",
    "pipeline2 = Pipeline([('vect', CountVectorizer()), ('trunc', TruncatedSVD()), ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier(random_state = 42)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning parameters and using them on GridSearchCV\n",
    "parameters3 = {'clf__estimator__learning_rate': [0.0001, 0.001, 1.0, 1.0],\n",
    "               'clf__estimator__n_estimators': [10, 50, 100, 500],\n",
    "               'clf__estimator__algorithm': [\"SAMME.R\", 'SAMME']}\n",
    "\n",
    "CV3 = GridSearchCV(pipeline2, param_grid = parameters3, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;trunc&#x27;, TruncatedSVD()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))]),\n",
       "             param_grid={&#x27;clf__estimator__algorithm&#x27;: [&#x27;SAMME.R&#x27;, &#x27;SAMME&#x27;],\n",
       "                         &#x27;clf__estimator__learning_rate&#x27;: [0.0001, 0.001, 1.0,\n",
       "                                                           1.0],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [10, 50, 100, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;trunc&#x27;, TruncatedSVD()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))]),\n",
       "             param_grid={&#x27;clf__estimator__algorithm&#x27;: [&#x27;SAMME.R&#x27;, &#x27;SAMME&#x27;],\n",
       "                         &#x27;clf__estimator__learning_rate&#x27;: [0.0001, 0.001, 1.0,\n",
       "                                                           1.0],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [10, 50, 100, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;trunc&#x27;, TruncatedSVD()),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('trunc', TruncatedSVD()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))]),\n",
       "             param_grid={'clf__estimator__algorithm': ['SAMME.R', 'SAMME'],\n",
       "                         'clf__estimator__learning_rate': [0.0001, 0.001, 1.0,\n",
       "                                                           1.0],\n",
       "                         'clf__estimator__n_estimators': [10, 50, 100, 500]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting GridsearchCV on training data\n",
    "CV3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict against the refined model with GriSearchCV and AdaBoostClassifier\n",
    "version3_model = CV3.best_estimator_\n",
    "y_predict_test3 = version3_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\magagunk\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_weighted</th>\n",
       "      <th>Recall_weighted</th>\n",
       "      <th>F1_Score_weighted</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_Score_macro</th>\n",
       "      <th>Precision_micro</th>\n",
       "      <th>Recall_micro</th>\n",
       "      <th>F1_Score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660781</td>\n",
       "      <td>0.737107</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>0.372534</td>\n",
       "      <td>0.348029</td>\n",
       "      <td>0.332952</td>\n",
       "      <td>0.737107</td>\n",
       "      <td>0.737107</td>\n",
       "      <td>0.737107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689706</td>\n",
       "      <td>0.830485</td>\n",
       "      <td>0.753577</td>\n",
       "      <td>0.415243</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>0.830485</td>\n",
       "      <td>0.830485</td>\n",
       "      <td>0.830485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>0.497482</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>0.994965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351193</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>0.441027</td>\n",
       "      <td>0.296308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372102</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>0.592615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843404</td>\n",
       "      <td>0.918370</td>\n",
       "      <td>0.879292</td>\n",
       "      <td>0.459185</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.478724</td>\n",
       "      <td>0.918370</td>\n",
       "      <td>0.918370</td>\n",
       "      <td>0.918370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.947513</td>\n",
       "      <td>0.921977</td>\n",
       "      <td>0.473756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.486525</td>\n",
       "      <td>0.947513</td>\n",
       "      <td>0.947513</td>\n",
       "      <td>0.947513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.952069</td>\n",
       "      <td>0.975740</td>\n",
       "      <td>0.963759</td>\n",
       "      <td>0.487870</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493861</td>\n",
       "      <td>0.975740</td>\n",
       "      <td>0.975740</td>\n",
       "      <td>0.975740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.964915</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.973530</td>\n",
       "      <td>0.491150</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495536</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.939900</td>\n",
       "      <td>0.969484</td>\n",
       "      <td>0.954463</td>\n",
       "      <td>0.484742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492253</td>\n",
       "      <td>0.969484</td>\n",
       "      <td>0.969484</td>\n",
       "      <td>0.969484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.876512</td>\n",
       "      <td>0.936222</td>\n",
       "      <td>0.905384</td>\n",
       "      <td>0.468111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483530</td>\n",
       "      <td>0.936222</td>\n",
       "      <td>0.936222</td>\n",
       "      <td>0.936222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.785579</td>\n",
       "      <td>0.886329</td>\n",
       "      <td>0.832918</td>\n",
       "      <td>0.443164</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469870</td>\n",
       "      <td>0.886329</td>\n",
       "      <td>0.886329</td>\n",
       "      <td>0.886329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.830562</td>\n",
       "      <td>0.911352</td>\n",
       "      <td>0.869084</td>\n",
       "      <td>0.455676</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476810</td>\n",
       "      <td>0.911352</td>\n",
       "      <td>0.911352</td>\n",
       "      <td>0.911352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.970318</td>\n",
       "      <td>0.985047</td>\n",
       "      <td>0.977627</td>\n",
       "      <td>0.492524</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.985047</td>\n",
       "      <td>0.985047</td>\n",
       "      <td>0.985047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.959826</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.969665</td>\n",
       "      <td>0.489854</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494875</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.979707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.983324</td>\n",
       "      <td>0.494431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.988862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.935467</td>\n",
       "      <td>0.967196</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.483598</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.491662</td>\n",
       "      <td>0.967196</td>\n",
       "      <td>0.967196</td>\n",
       "      <td>0.967196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.911422</td>\n",
       "      <td>0.954684</td>\n",
       "      <td>0.932552</td>\n",
       "      <td>0.477342</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488408</td>\n",
       "      <td>0.954684</td>\n",
       "      <td>0.954684</td>\n",
       "      <td>0.954684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753723</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.806909</td>\n",
       "      <td>0.434086</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464717</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.868172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.878513</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.906950</td>\n",
       "      <td>0.468645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483815</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.937290</td>\n",
       "      <td>0.937290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.909675</td>\n",
       "      <td>0.953769</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>0.476884</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488169</td>\n",
       "      <td>0.953769</td>\n",
       "      <td>0.953769</td>\n",
       "      <td>0.953769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.903863</td>\n",
       "      <td>0.950717</td>\n",
       "      <td>0.926698</td>\n",
       "      <td>0.475359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.487368</td>\n",
       "      <td>0.950717</td>\n",
       "      <td>0.950717</td>\n",
       "      <td>0.950717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.955645</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.488785</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494329</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.977571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.990169</td>\n",
       "      <td>0.496720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498354</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.993439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.982984</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>0.987202</td>\n",
       "      <td>0.495728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497855</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>0.991456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.975435</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.493821</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496891</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.987641</td>\n",
       "      <td>0.987641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>0.478410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.956820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.532138</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>0.364739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421791</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.729478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.847894</td>\n",
       "      <td>0.920812</td>\n",
       "      <td>0.882850</td>\n",
       "      <td>0.460406</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.479387</td>\n",
       "      <td>0.920812</td>\n",
       "      <td>0.920812</td>\n",
       "      <td>0.920812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.823901</td>\n",
       "      <td>0.907690</td>\n",
       "      <td>0.863768</td>\n",
       "      <td>0.453845</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475806</td>\n",
       "      <td>0.907690</td>\n",
       "      <td>0.907690</td>\n",
       "      <td>0.907690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.979961</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>0.984920</td>\n",
       "      <td>0.494965</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497470</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>0.989930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.828061</td>\n",
       "      <td>0.909979</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.454989</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.909979</td>\n",
       "      <td>0.909979</td>\n",
       "      <td>0.909979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.957436</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.967847</td>\n",
       "      <td>0.489243</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494563</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>0.978486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.486886</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.948886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.649507</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>0.719309</td>\n",
       "      <td>0.402960</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.446266</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>0.805920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision_weighted  Recall_weighted  F1_Score_weighted  Precision_macro  \\\n",
       "0             0.660781         0.737107           0.674399         0.372534   \n",
       "1             0.689706         0.830485           0.753577         0.415243   \n",
       "2             0.989955         0.994965           0.992454         0.497482   \n",
       "3             0.351193         0.592615           0.441027         0.296308   \n",
       "4             0.843404         0.918370           0.879292         0.459185   \n",
       "5             0.897781         0.947513           0.921977         0.473756   \n",
       "6             0.952069         0.975740           0.963759         0.487870   \n",
       "7             0.964915         0.982301           0.973530         0.491150   \n",
       "8             0.939900         0.969484           0.954463         0.484742   \n",
       "9             1.000000         1.000000           1.000000         1.000000   \n",
       "10            0.876512         0.936222           0.905384         0.468111   \n",
       "11            0.785579         0.886329           0.832918         0.443164   \n",
       "12            0.830562         0.911352           0.869084         0.455676   \n",
       "13            0.970318         0.985047           0.977627         0.492524   \n",
       "14            0.959826         0.979707           0.969665         0.489854   \n",
       "15            0.977848         0.988862           0.983324         0.494431   \n",
       "16            0.935467         0.967196           0.951067         0.483598   \n",
       "17            0.911422         0.954684           0.932552         0.477342   \n",
       "18            0.753723         0.868172           0.806909         0.434086   \n",
       "19            0.878513         0.937290           0.906950         0.468645   \n",
       "20            0.909675         0.953769           0.931200         0.476884   \n",
       "21            0.903863         0.950717           0.926698         0.475359   \n",
       "22            0.955645         0.977571           0.966484         0.488785   \n",
       "23            0.986921         0.993439           0.990169         0.496720   \n",
       "24            0.982984         0.991456           0.987202         0.495728   \n",
       "25            0.992690         0.996338           0.994511         0.498169   \n",
       "26            0.975435         0.987641           0.981500         0.493821   \n",
       "27            0.915505         0.956820           0.935707         0.478410   \n",
       "28            0.532138         0.729478           0.615375         0.364739   \n",
       "29            0.847894         0.920812           0.882850         0.460406   \n",
       "30            0.823901         0.907690           0.863768         0.453845   \n",
       "31            0.979961         0.989930           0.984920         0.494965   \n",
       "32            0.828061         0.909979           0.867089         0.454989   \n",
       "33            0.957436         0.978486           0.967847         0.489243   \n",
       "34            0.900385         0.948886           0.924000         0.474443   \n",
       "35            0.649507         0.805920           0.719309         0.402960   \n",
       "\n",
       "    Recall_macro  F1_Score_macro  Precision_micro  Recall_micro  \\\n",
       "0       0.348029        0.332952         0.737107      0.737107   \n",
       "1       0.500000        0.453697         0.830485      0.830485   \n",
       "2       0.500000        0.498738         0.994965      0.994965   \n",
       "3       0.500000        0.372102         0.592615      0.592615   \n",
       "4       0.500000        0.478724         0.918370      0.918370   \n",
       "5       0.500000        0.486525         0.947513      0.947513   \n",
       "6       0.500000        0.493861         0.975740      0.975740   \n",
       "7       0.500000        0.495536         0.982301      0.982301   \n",
       "8       0.500000        0.492253         0.969484      0.969484   \n",
       "9       1.000000        1.000000         1.000000      1.000000   \n",
       "10      0.500000        0.483530         0.936222      0.936222   \n",
       "11      0.500000        0.469870         0.886329      0.886329   \n",
       "12      0.500000        0.476810         0.911352      0.911352   \n",
       "13      0.500000        0.496234         0.985047      0.985047   \n",
       "14      0.500000        0.494875         0.979707      0.979707   \n",
       "15      0.500000        0.497200         0.988862      0.988862   \n",
       "16      0.500000        0.491662         0.967196      0.967196   \n",
       "17      0.500000        0.488408         0.954684      0.954684   \n",
       "18      0.500000        0.464717         0.868172      0.868172   \n",
       "19      0.500000        0.483815         0.937290      0.937290   \n",
       "20      0.500000        0.488169         0.953769      0.953769   \n",
       "21      0.500000        0.487368         0.950717      0.950717   \n",
       "22      0.500000        0.494329         0.977571      0.977571   \n",
       "23      0.500000        0.498354         0.993439      0.993439   \n",
       "24      0.500000        0.497855         0.991456      0.991456   \n",
       "25      0.500000        0.499083         0.996338      0.996338   \n",
       "26      0.500000        0.496891         0.987641      0.987641   \n",
       "27      0.500000        0.488967         0.956820      0.956820   \n",
       "28      0.500000        0.421791         0.729478      0.729478   \n",
       "29      0.500000        0.479387         0.920812      0.920812   \n",
       "30      0.500000        0.475806         0.907690      0.907690   \n",
       "31      0.500000        0.497470         0.989930      0.989930   \n",
       "32      0.500000        0.476434         0.909979      0.909979   \n",
       "33      0.500000        0.494563         0.978486      0.978486   \n",
       "34      0.500000        0.486886         0.948886      0.948886   \n",
       "35      0.500000        0.446266         0.805920      0.805920   \n",
       "\n",
       "    F1_Score_micro  \n",
       "0         0.737107  \n",
       "1         0.830485  \n",
       "2         0.994965  \n",
       "3         0.592615  \n",
       "4         0.918370  \n",
       "5         0.947513  \n",
       "6         0.975740  \n",
       "7         0.982301  \n",
       "8         0.969484  \n",
       "9         1.000000  \n",
       "10        0.936222  \n",
       "11        0.886329  \n",
       "12        0.911352  \n",
       "13        0.985047  \n",
       "14        0.979707  \n",
       "15        0.988862  \n",
       "16        0.967196  \n",
       "17        0.954684  \n",
       "18        0.868172  \n",
       "19        0.937290  \n",
       "20        0.953769  \n",
       "21        0.950717  \n",
       "22        0.977571  \n",
       "23        0.993439  \n",
       "24        0.991456  \n",
       "25        0.996338  \n",
       "26        0.987641  \n",
       "27        0.956820  \n",
       "28        0.729478  \n",
       "29        0.920812  \n",
       "30        0.907690  \n",
       "31        0.989930  \n",
       "32        0.909979  \n",
       "33        0.978486  \n",
       "34        0.948886  \n",
       "35        0.805920  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe to view the results from the AdaBoostClassifier\n",
    "Test_Report3 = []\n",
    "for m, column in enumerate(y_test.columns):\n",
    "    Report1 = Precision_recall_f1_score(y_test.loc[:,column], y_predict_test3[:, m])\n",
    "    Test_Report3.append(Report1)\n",
    "Test_Report3_df = pd.DataFrame(Test_Report3)\n",
    "Test_Report3_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision_weighted    0.869763\n",
       "Recall_weighted       0.926733\n",
       "F1_Score_weighted     0.895238\n",
       "Precision_macro       0.477366\n",
       "Recall_macro          0.509667\n",
       "F1_Score_macro        0.491142\n",
       "Precision_micro       0.926733\n",
       "Recall_micro          0.926733\n",
       "F1_Score_micro        0.926733\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the scores\n",
    "Test_Report3_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will use the RandomForestClassifier with the GridsearchCV as it performed better than the AdaBoostClassifier\n",
    "# Taking RandomForestClassifier with the GridsearchCV is a good opting as it prevents data leakage \n",
    "\n",
    "filename = 'CV.pkl'\n",
    "pickle.dump(CV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
